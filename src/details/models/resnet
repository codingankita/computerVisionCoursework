This is a PyTorch implementation of Residual Networks (ResNet) for image classification. ResNet is a deep neural network architecture that introduces residual connections to help alleviate the vanishing gradient problem in deep networks. 

The code defines several ResNet variants: `resnet18`, `resnet18_fc512`, `resnet34`, `resnet34_fc512`, `resnet50`, and `resnet50_fc512`. 

Here's a detailed explanation of each line of the code:

```python
# Copyright (c) EEEM071, University of Surrey

# Import required packages
import torch
import torch.utils.model_zoo as model_zoo
import torchvision
from torch import nn
from torch.nn import functional as F

# Define the models to be exported
__all__ = [
    "resnet18",
    "resnet18_fc512",
    "resnet34",
    "resnet34_fc512",
    "resnet50",
    "resnet50_fc512",
]

# Define the model URLS for pre-trained models
model_urls = {
    "resnet18": "https://download.pytorch.org/models/resnet18-5c106cde.pth",
    "resnet34": "https://download.pytorch.org/models/resnet34-333f7ec4.pth",
    "resnet50": "https://download.pytorch.org/models/resnet50-19c8e357.pth",
    "resnet101": "https://download.pytorch.org/models/resnet101-5d3b4d8f.pth",
    "resnet152": "https://download.pytorch.org/models/resnet152-b121ed2d.pth",
}
```

The code imports necessary packages and defines the ResNet models that will be exported. It also sets the URLs to download pre-trained ResNet models.

```python
# Define a 3x3 convolution with padding function
def conv3x3(in_planes, out_planes, stride=1):
    return nn.Conv2d(
        in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False
    )


# Define a basic block for ResNet
class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super().__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out
```

This defines a basic building block of ResNet, called `BasicBlock`. It consists of two convolutional layers with batch normalization and ReLU activations, followed by a residual connection.

```python
# Define a bottleneck block for ResNet
class Bottleneck(nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super().__init__()
        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
        self.bn1 = nn
        
```
class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super().__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out
```
- `BasicBlock` is a class that inherits from `nn.Module`. It defines the basic building block for the ResNet architecture.
- The class variable `expansion` is set to 1, indicating that this basic block doesn't change the number of channels in the input feature maps.
- The constructor (`__init__`) takes in four parameters:
  - `inplanes`: The number of channels in the input feature maps.
  - `planes`: The number of channels in the output feature maps.
  - `stride`: The stride of the first convolutional layer.
  - `downsample`: A module that performs downsampling (e.g. by strided convolution) on the input feature maps. This is used when the number of channels in the input feature maps doesn't match the number of channels in the output feature maps, or when the spatial resolution of the input feature maps needs to be reduced.
- In the constructor, two convolutional layers are defined: `conv1` and `conv2`. `conv1` is a 3x3 convolutional layer with `stride` stride, and `conv2` is another 3x3 convolutional layer.
- Two batch normalization layers (`bn1` and `bn2`) are defined, one for each convolutional layer.
- An instance of the ReLU activation function is defined (`relu`).
- The `downsample` module, if provided, is stored as an instance variable.
- The `stride` parameter is stored as an instance variable.
- The `forward` method takes in a tensor `x` and returns the output of the basic block. The input tensor `x` is stored in the `residual` variable. The input tensor `x` is passed through `conv1`, `bn1`, and `relu`, and the resulting tensor is passed through `conv2` and `bn2`. If the `downsample` module is provided, `residual` is passed through it. Finally, the output of the `downsample` module (if provided) is added to the output of `bn2`, and the result is passed through `relu` and returned.
